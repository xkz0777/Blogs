---
title: 数据结构——散列表
date: 2021-09-13 12:27:18
tags: 数据结构
author: xkz
categories: 数据结构
mathjax: true
img: /medias/featureimages/sjjg7.jpg
summary: 数据结构——散列表
---

# 散列表

查找的本质是已知对象找其位置。

1. 有序安排对象：全序（即排好序的数组，查找时使用二分查找）、半序（即维护一棵搜索树）。
2. 直接算出对象的位置：即下面要介绍的散列表。

散列表，又称为哈希表（Hash Table），是一个存储关键字对应记录（下面简称记录）的数组，通过散列函数计算出关键字存储在表中的位置来进行查找的过程称为散列查找。

散列查找法的两项基本工作：

1. 计算位置：**构造散列函数**确定关键字存储位置。
2. 解决冲突：应用某种策略解决多个关键字位置相同的问题。

其时间复杂度几乎是常量：$O(1)$，其**查找时间仅仅取决于散列函数的执行时间，与问题的规模无关**。

散列（Hashing）的基本思想是：

1. 以关键字 key 为自变量，通过一个确定的散列函数 h，计算出对应的函数值 h(key)，作为数据对象的存储地址。
2. 对于不同关键字映射到同一个散列地址上的情况，称为冲突（Collision），需要某种冲突解决策略。

## 散列函数的设计

装填因子（Loading Factor）：设散列表空间大小为 $m$，填入表中元素个数是 $n$，则称 $\alpha=n/m$ 为散列表的装填因子。

装填因子 $\alpha$ 不宜太大或太小，太小时，会引起空间的浪费；太大时，容易发生冲突，而冲突的解决往往是比较费时的。

散列函数在设计时，一般考虑下列两个因素：

1. 计算简单，以便提高转换速度。
2. 关键词对应的地址空间分布均匀，以尽量减小冲突。

### 数字关键字的散列函数构造

1. 线性函数

	顾名思义，取关键字的某个线性函数值为散列地址，即 $h(key)=a* key+b$。

	例如：存储从 `2010` 到 `2020` 年每年的出生人数，构造 $h(key)=key-2010$。

2. 取模

	一般选取哈希表的表长作为除数，即 $h(key)=key\mod tableSize$。且表长一般选取素数。

	例如：有 `n = 11` 个数据对象的集合`{18, 23, 11, 20, 2, 7, 27, 30, 42, 15, 34}`。

	取 $tableSize=17$，选取散列函数 $h(key)=key \mod 17$。

	此时会发现 `18` 和 `35` 的散列值相同，出现冲突，在后面介绍冲突处理策略。

3. 数据分析法

	分析数字关键字在各位上的变化情况，取比较随机的位作为散列地址。即对 $key=n_0n_1\dots n_k$，取 $h(key)=n_{i_0}n_{i_1}\dots n_{i_m}$，其中 $i_0i_1\dots i_m$ 为 $01\dots k$ 的子列。

	例如：取 `11` 位手机号码 `key` 的后四位作为地址。

4. 折叠法

	把关键字分割成位数相同的几个部分，然后叠加。

	例如：对 $key=56793542$，分成 `056、793、542`，然后相加，得到 `1391`。同样的取三位，得到最终 $h(key)=391$。

5. 平方取中法

	把关键字平方，然后取中间的 `k` 位。

	例如，对 $key=56793542$，平方得 $3225506412905764$，取中间三位，$h(key)=641$。

### 字符关键字的散列函数构造

1. `ASCII` 码加和法：把所有数位的 `ASCII` 码相加，此时可能超过 `tableSize`，需要取模，即对 $key=s_0s_1\dots s_n$ $h(key)=\sum\limits_{i=0}^ nkey[i]\mod tableSize$

2. 移位法：
	$$
	h(key)=\sum\limits_{i=0}^{n-1}key[n-i-1]*base^i\mod{tableSize}
	$$
	这里应该注意 `base` 的取法：通常 `base` 会取一个比字符串中可能出现的字符数目更多的素数，例如对于数字字符串，可以取 `base = 31`（也可以取 `base = 32`，这时计算哈希值时可以用位运算），对于所有字符都可能出现的字符串，由于 `ASCII` 码一共有 `127` 个字符，因此我们可以取 `base = 131`。

	同时，在计算哈希值时，如果懒得取模，可以利用 `unsigned long long` 溢出相当于取模的特性（当然哈希表不可能开 `unsigned long long` 那么大，取得哈希值后还要再模表长）。

	上面的字符串哈希方式称为单哈希（即自然溢出和取一个大质数作为模数），单哈希可能还是会出现重复的情况，因此可以选择两个大质数 `mod1` 和 `mod2` 作为模数，用得到的哈希值模两个模数，得到的二元组存进哈希表中，这样的方式称为双哈希，双哈希比单哈希要安全得多。

## 冲突处理方法

无论用什么办法处理冲突，在可能出现冲突的问题中，一定要把 `key、value` 整个键值对插入哈希表，否则在查找时无法分辨哪个是需要的数据。

1. 链地址法：当多个关键字最后寻找到哈希表的地址相同时，我们可以在该位置维护一个单链表（通常在 C++ 中的实现方式为开一个 `vector<vector<ElementType>> hashTable` 作为哈希表）。

2. 线性探测法

	以线性序列（如 `1、2、...、n`）循环试探下一个存储地址，该方式查找失败时存在弊端：只有一直试探到某个位置没有存储信息，又或是已经循环遍历了哈希表一遍，才能断定查找失败。

3. 平方探测法

	用二次序列（`1、-1、4、-4、...、n²、-n²`）循环试探下一个存储地址。该方式除了有线性探测的弊端外，还存在可能无法探查到整个散列表空间的问题。有定理表明，如果散列表长度 `tableSize` 是某个 `4k + 3` 形式的素数时，平方探测法就可以探查到整个散列表空间。

4. 双散列探测法

	探测序列 $d_i=i*h_2(key)$，其中 $h_2(key)$ 是另一个散列函数，通常选择如下形式有良好的效果：
	$$
	h_2(key)=p-(key\:\:mod \:\:{p})
	$$
	其中 $p<tableSize$，$p、tableSize$ 都是素数。

5. 再散列法

	当散列表元素太多（装填因子 $\alpha$ 太大）时，查找效率会下降，一般应该保持 $0.5\le \alpha\le 0.95$。过大时应该加倍扩大散列表，这个过程叫做再散列（Rehashing）。

## 例题

### 文件中单词词频统计

#### 题目描述

给定一个英文文本文件，统计文件中所有单词出现的频率，并输出词频最大的前 10% 的单词及其词频。
假设单词字符定义为大小写字母、数字和下划线，其它字符均认为是单词分隔符，不予考虑。

#### 解题思路

本题实际上是一个“关联数组”问题，关联数组即下标为字符串（或其他非数字类型）的“数组”（在 Python 中为字典）。我们希望能够写出形如 `frequency["this"] = 2` 这样的语句，可以在 $O(N)$ 的时间内完成对整个文本的词频统计（其中 `N` 为单词个数）。

我们在哈希表中存储的元素为 `pair<string, int>` 类型，用链地址法处理冲突即可，之后对该 `vector` 排序，输出词频前 10% 的单词和词频即可。总的时间复杂度为 $O(NlogN)$。

